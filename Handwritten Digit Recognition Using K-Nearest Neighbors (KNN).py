# -*- coding: utf-8 -*-
"""tp handwritten digit recognition with KNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3OrX9bD_7WfClsWe4UX4hxRswX1wHLe
"""

from sklearn import datasets
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

mnist=datasets.load_digits()#load mnist dataset
img=np.array(mnist.images) #img=(1797,8,8) array(mnist image)
data_size=mnist.target.size
arr_img_rows=8
arr_img_cols=8
nrow_subarr=4# zonage
ncol_subarr=2#zonage
nbr_zone=64//(ncol_subarr*nrow_subarr)
sill=8#seuil pour la binarization

#function for images binarization (0,1) sill=seuil (-- Prétraitement--- )
def Binarisation(sill):
    for k in range(data_size):
        for i in range(arr_img_rows):
            for j in range(arr_img_cols):
                if (img[k][i][j]<sill) :
                    img[k][i][j]=0
                else:
                    img[k][i][j]=1
    return img

#----fonction pour la projection Horizontal-Vertical respectivement des images
def Projection_H_V():
    sized=arr_img_rows+arr_img_cols #necessary size array of features
    data_set_P = np.empty((0, sized), int)
    for k in range(data_size):
        data = np.empty((0, sized), int)
        for i in range(arr_img_rows):#projection horizontal
            ph = 0
            for j in range(arr_img_cols):
                if img[k][i][j] == 1:
                    ph += 1
            data = np.array(np.append(data, ph,))
        for i in range(arr_img_rows):#projection vertical
            pv = 0
            for j in range(arr_img_cols):
                if img[k][j][i] == 1:
                    pv += 1
            data = np.array(np.append(data, pv))
        data_set_P = np.vstack([data_set_P, data])#featurs array prj_hv
    return data_set_P

#----fonction pour le zonage de l'image en quatre zonees
def blockshaped(arr, nrows, ncols):#blockshaped array of image
    """
    Return an array of shape (n, nrows, ncols) where
    n * nrows * ncols = arr.size
    """
    h, w = arr.shape
    assert h % nrows == 0, f"{h} rows is not evenly divisible by {nrows}"
    assert w % ncols == 0, f"{w} cols is not evenly divisible by {ncols}"
    return (arr.reshape(h//nrows, nrows, -1, ncols)
               .swapaxes(1,2)
               .reshape(-1, nrows, ncols))
#----------------------------------------------------------------------------
def Zonage (nrow_subarr,ncol_subarr):#extract image features from areas(zone)
    data_set_Z=np.empty((0,nbr_zone),int)
    for m in range(data_size):
        zone=np.array(blockshaped(img[m],nrow_subarr,ncol_subarr))
        data=np.empty((0,nbr_zone),int)
        for k in range(nbr_zone):
            nbr=0
            for i in range(nrow_subarr):
                for j in range(ncol_subarr):
                    if zone[k][i][j]==1:
                        nbr+=1
            data=np.array(np.append(data,nbr))
        data_set_Z=np.vstack([data_set_Z,data])
    return data_set_Z

#------function Character Shape Profiles---------------
def char_prof():
    data_set_CP = np.empty((0,arr_img_cols*2), int)
    for k in range(data_size):
        dis_edge_l= np.empty((0,arr_img_cols), int)
        dis_edge_r= np.empty((0,arr_img_cols), int)
        for i in range(arr_img_rows):
            dis_ed=0
            for j in range(arr_img_cols):
                if (img[k][i][j]==0):
                    dis_ed+=1
                else:
                    break
            dis_edge_l=np.array(np.append(dis_edge_l,dis_ed))
            dis_ed=0
            for j in range(arr_img_cols-1,-1,-1):
                if (img[k][i][j]==0):
                    dis_ed+=1
                else:
                    break
            dis_edge_r=np.array(np.append(dis_edge_r,dis_ed))
        data=np.hstack([dis_edge_l,dis_edge_r])
        data_set_CP=np.vstack([data_set_CP,data])
    return data_set_CP

#Euclidean_dist between exp1_exp2
def distance_euc(x1, x2):
    return np.sum((x1 - x2)**2)**0.5

def areDistinct(arr) :
    n = len(arr)
    s = set()
    for i in range(0, n):
        s.add(arr[i])
    return (len(s) == len(arr))
#k-nearest neighbor function
#k-nearest neighbor function
def kNN(X_train, y_train, x_test,y_test, k ):
    """
    X_train- > (m, 20)  np array (m is nbr of eg. images)
    y_train- > (m,) np array (targets array)
    x_test -> (1,20) np array(image which you want classified X_test[i])
    k -> scaler  int (the k of nearest neaghbor)

    do knn for classification
    """
    m = X_train.shape[0]
    distances = []
    dist = []
    labels=[]
    for i in range(m):
        dis = distance_euc(x_test,X_train[i])
        distances.append((dis,y_train[i]))
        dist.append(dis)

    dist=sorted(dist)#list of sorted distance only
    #dist=np.array(dist[:k])
    distances = sorted(distances)#liste triée(sorted list -->min to max)
    distances=np.array(distances)
    labels=distances[:, 1]
    distances_k = distances[:k] #array of the k min distances
    distances_k = np.array(distances_k)
    labels_k = distances_k[:, 1]

    #uniq_lable=array of k 1er exp sans recurrence//count
    uniq_label, counts = np.unique(labels_k, return_counts=True)#turn arry  nbr  occurrence
    counts=np.array(counts)
    if areDistinct(counts):
        pred = uniq_label[counts.argmax()]
    else:
        #pred=y_test
        maxe=np.max(counts)
        index_all_occ=np.array(np.where(counts==maxe)[0])
        lab_non_occ=np.array([])
        for i in index_all_occ:
            lab_non_occ=np.append(lab_non_occ,uniq_label[i])#
        lab_non_occ=np.array(lab_non_occ)
        em_arr=np.array([])
        for j in lab_non_occ:
            em=0
            co=0
            for l in range(len(labels)):
                if j==labels[l] :
                    em+=dist[l]
                    co+=1
            em_arr=np.append(em_arr,em/co)
        pred=lab_non_occ[em_arr.argmin()]

    return int(pred)
# prediciting label for test

def accuracy(k):
    ac=0
    for i in range(y_test.size):
        pred=kNN(X_train , y_train, X_test[i],y_test[i], k)
        if pred==y_test[i]:
            ac+=1
    ac=((ac/y_test.size)*100)
    return ac

K_arr=accarr=lossarr=np.empty((0,29))
Binarisation(sill)
mnist_data=np.hstack([Projection_H_V(),Zonage(nrow_subarr, ncol_subarr),Zonage(ncol_subarr,nrow_subarr),char_prof()])#the features concatenate
#diviser le dataset 25% for test and 75% for training
X_train, X_test, y_train, y_test,imgtrain,imgtest= train_test_split(mnist_data, mnist.target,mnist.images,test_size=0.25,random_state=0)
#X_train, X_test, y_train, y_test,imgtrain,imgtest= train_test_split(mnist_data, mnist.target,mnist.images,test_size=0.25,random_state=0)
for k in range(1,6,1):
    K_arr=np.append(K_arr,k)
    accarr=np.append(accarr,accuracy(k))
    lossarr=np.append(lossarr,100-accuracy(k))
print ("the best accuracy is",max(accarr),"for k=",accarr.argmax()+1)
plt.plot(K_arr,accarr)
plt.legend(['accuracy rate '], loc='lower left')
plt.title('accuracy  rate test plot ')
plt.ylabel('accuracy')
plt.xlabel('value of  the K nearset')
plt.show()

plt.plot(K_arr,lossarr)
plt.legend(['error rate '], loc='lower left')
plt.title('error rate test plot ')
plt.ylabel('error')
plt.xlabel('value of  the K nearset')
plt.show()